---
title: '<center> <h1>Análisis de supervivencia y de datos longitudinales (M0-161)</h1> </center>'
author: "María Plaza García - DNI 45735741"
subtitle: '`r params$subtitulo`'
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
citecolor: blue
urlcolor: blue
output:
  html_document:
    df_print: paged
    toc: yes
    fig_caption: yes
    toc_float: true
    theme: united
    highlight: tango
    toc_depth: 3
  pdf_document: 
    fig_caption: yes
    highlight: tango
    keep_tex: yes
    latex_engine: xelatex
    number_sections: yes
    toc: yes
    toc_depth: 3
  word_document:
    toc: true
link-citations: yes
nocite: |
  @kleinbaum2010survival
  @galecki2013linear
  @therneau2014package
header-includes:
  - \usepackage[spanish]{babel}
  - \usepackage{subfig}
params:
  subtitulo: Tercera prueba de evaluación continua - dataset ARMD
  p.train: !r 150
  seed.train: 41
  seed.clsfier: 1234
bibliography: PEC3.bib
geometry: margin=2cm
---

```{r setup, include=FALSE}
require(knitr)
knitr::opts_chunk$set(
  fig.show = "hold",
  fig.align='center',
  fig.height = 4.5,
  fig.width = 5,
	message = FALSE,
	warning = FALSE,
	cache = TRUE,
	comment = NULL,
	tidy = FALSE
)
options(width=90)
Sys.setlocale("LC_TIME", "C")
```

```{r packages, message=FALSE, echo=FALSE, warning=FALSE}
libraries <- c("htmltools", "bookdown", "bibtex" ,"survival", "KMsurv",
               "survMisc", "ggfortify", "knitr", "flexsurv", "actuar", "dplyr", "printr", "nlmeU")
check.libraries <- is.element(libraries, installed.packages()[, 1])==FALSE
libraries.to.install <- libraries[check.libraries]
if (length(libraries.to.install!=0)) {
  install.packages(libraries.to.install)
}

success <- sapply(libraries,require, quietly = FALSE,  character.only = TRUE)
if(length(success) != length(libraries)) {stop("A package failed to return 
                                               a success in require() function.")}

```

**Repositorio Github:**

https://github.com/mariaplaza/PEC3_DatosLongitudinales

\pagebreak

# Introducción

Reproducir el análisis estadístico completo que se lleva a cabo en la selección de GB13 para el el conjunto ARMD para el dataset personal. Desde la presentación y descripción del dataset objeto de estudio hasta el modelo lineal mixto que se proponga, cada paso debe ser oportunamente motivado y razonado, con la interpretación final de los resultados.

Los modelos mixtos son usados cuando los datos tienen alg´un tipo de estructura jer´arquica o de agrupaci´on como los dise˜nos de medidas repetidas,las series temporales, los dise˜nos anidados o por bloques aleatorizados. Los modelos mixtos permiten tener coeﬁcientes ﬁjos (aquellos cuyos niveles son de inter´es para el experimentador) y aleatorios (aquellos cuyos niveles son s´olo una realizaci´on de todos los posibles niveles procedentes de una poblaci´on) y varios t´erminos de error. Pueden ser una herramienta muy ´util, pero son potencialmente dif´ıciles de comprender y aplicar.

Para ello se emplea espewcialmente el paquete `nlme()` escrito inicialmente por Jose Pinheiro (Bell Laboratories) y Douglas Bates (University of Wisconsin). 

# Datos
## Selección de la muestra estudio

Vamos a emplear los datos ARMD disponibles en el paquete `nlmeU` como data frame. Los datos de ARMD surgen de un ensayo clínico aleatorizado multicéntrico que compara un tratamiento experimental (interferón alfa) versus placebo para pacientes diagnosticados con ARMD, de las siglas en inglés, Age-Related Macular Degeneration (La degeneración macular relacionada con la edad).

```{r}
library(nlmeU)
attach(armd.wide)
attach(armd0)
attach(armd)
dim(armd.wide)
str(armd.wide)
dim(armd0)
```

Vemos que se trata de un data frame con datos de 240 pacientes sobre 10 variables de tipo numéricas y facores.

En primer lugar debemos hacer una selección del dataset con la información de 150 individuos escogidos de forma aleatoria del dataset original `armd.wide`, a partir de las dos últimas cifras del NIF, en este caso *41*, siguiendo las siguientes indicaciones:

```{r}
#fijamos la semilla para el generador pseudoaleatorio
set.seed(params$seed.train) 
# creamos la muestra de 150 individuos
muestra<-sample(1:nrow(armd.wide),params$p.train)
my.armd.wide <- data.frame(armd.wide[muestra,])
dim(my.armd.wide) # vemos que se ha creado adecuadamente
# write.csv(my.armd.wide, "./my.armd.wide.csv") # guardamos la seleccion
head(my.armd.wide)
```

Con los datos de estos pacientes, reducimos los otros dos conjuntos de datos de armd, armd y armd0, para que contengan los datos de los mismos pacientes de mi selección. Tenemos por tanto, tres conjunto de datos de 150 pacientes en tres diferentes data.frame:

```{r}
library(dplyr)
my.armd0 <- filter(armd0, subject %in% my.armd.wide$subject)
dim(my.armd0)

library(dplyr)
my.armd <- filter(armd, subject %in% my.armd.wide$subject)
dim(my.armd)
```

Veamos cuales de las características actúan como factores:
```{r}
(facs <- sapply(my.armd.wide, is.factor))

names(facs[facs == TRUE])
```

Interesante es el factor `miss.pat`, creado con los valores de las columnas visual4, visual12, visual24, y visual52. Los elementos del vector `miss.pat` resultante indican que, por ejemplo, para el paciente 163 en el marco de datos faltaban mediciones de agudeza visual en la semana 24 y 52, mientras que para paciente 5, no se obtuvieron mediciones de agudeza visual en cualquier visita posterior a la aleatorización inicial.

## Exploración de la muestra estudio
### ARMD Trial: Visual Acuity

En los datos de ARMD, estamos interesados principalmente en el efecto del tratamiento sobre las mediciones de agudeza visual. Por lo tanto, en la Fig. 3.1, primero observamos las mediciones trazándolas contra el tiempo para varios pacientes seleccionados de ambos grupos de tratamiento. Más específicamente, seleccionamos cada 10 pacientes de cada grupo. En base a los gráficos que se muestran en la figura 3.1, se pueden realizar varias observaciones

```{r}
library(lattice)

xy1 <- # Draft plot
xyplot(visual ~ jitter(time) | treat.f,
groups = subject,
data = my.armd0,
type = "l", lty = 1)
update(xy1, # Fig. 3.1
xlab = "Time (in weeks)",
ylab = "Visual acuity",
grid = "h")

library(ggplot2)
library(nlmeU) 
ggplot(my.armd0, aes(x=time, y=visual, group=subject, color=treat.f)) + geom_line()+geom_point()+xlab("Tiempo (semanas)")+ylab("Agudeza Visual")

```

### Patterns of Missing Data

Inspección de patrones de datos faltantes en los datos de armd.wide para las mediciones de agudeza visual posteriores a la aleatorización utilizando tres métodos diferentes

```{r}
table(my.armd.wide$miss.pat)

with(my.armd.wide, table(miss.pat))

xtabs(~miss.pat, my.armd.wide)
```

También vale la pena señalar que hay seis (= 3 + 1 + 1 + 1) pacientes con cuatro patrones diferentes de datos faltantes no monótonos, es decir, con mediciones intermitentes de agudeza visual faltante. Al modelar datos con tales patrones, se necesita un cuidado adicional al especificar estructuras de varianza-covarianza. 

### Mean-Value Profiles

En esta sección, investigamos el número de valores faltantes y calculamos las medias de muestra de las mediciones de agudeza visual para diferentes visiones y grupos de tratamiento.

```{r}
# Counts of nonmissing visual acuity measurements
attach(my.armd0)
flst <- list(time.f, treat.f) # "By" factors
(tN <- # Counts
tapply(visual, flst,
FUN = function(x) length(x[!is.na(x)])))
```

Como resultado, obtenemos una matriz con el número de mediciones de agudeza visual que no faltan para cada visita y cada grupo de tratamiento. Almacenamos la matriz en el objeto tN. La visualización de la matriz indica que no faltaron mediciones al inicio. En general, hay más mediciones faltantes en el grupo de tratamiento activo.

En la siguiente tabla, empleamos de nuevo la función `tapply()` dos veces para calcular las medias y las medianas de la muestra de las mediciones de agudeza `visual0` para cada combinación de los niveles de factores line0 y treat.f. Almacenamos los resultados en matrices tMn y tMd, respectivamente. Luego creamos la matriz `res` combinando matrices tN, tMn y tMn por columnas. Finalmente, para mejorar la legibilidad de las pantallas, modificamos los nombres de las columnas de resolución.

A partir de la visualización de la matriz de resolución, se concluye que, en promedio, hubo muy poca diferencia en la agudeza visual entre los dos grupos de tratamiento al inicio del estudio. Durante el curso del estudio, la agudeza visual media disminuyó con el tiempo en ambos grupos. El valor medio es consistentemente mayor en el grupo placebo.

```{r}
# Sample means and medians of visual acuity measurements
attach(my.armd0)
tMn <- tapply(visual, flst, FUN = mean) # Sample means
tMd <- tapply(visual, flst, FUN = median) # Sample medians
colnames(res <- cbind(tN, tMn, tMd)) # Column names

nms1 <- rep(c("P", "A"), 3)
nms2 <- rep(c("n", "Mean", "Mdn"), rep(2, 3))
colnames(res) <- paste(nms1, nms2, sep = ":") # New column names
res
detach(my.armd0)
```

La siguiente figura muestra gráficos de caja para la agudeza visual de los cinco puntos temporales y los dos grupos de tratamiento.

```{r}
library(lattice)
bw1 <- # Draft plot
bwplot(visual ~ time.f | treat.f,
data = my.armd0)
xlims <- c("Base", "4\nwks", "12\nwks", "24\nwks", "52\nwks")
update(bw1, xlim = xlims, pch = "|") # Final plot
```

Las gráficas de caja y bigotes ilustran los patrones implicados por las medias y medianas de muestra, presentadas en el Panel R3.3b. La disminución de los valores medios en el tiempo se ve claramente para ambos grupos de tratamiento. Es más pronunciado para el brazo de tratamiento activo. Como hubo un abandono ligeramente mayor en ese brazo, una posible explicación podría ser que los pacientes cuya agudeza visual mejoró abandonaron el estudio. En tal caso, se observaría una progresión más rápida de la enfermedad en ese brazo de tratamiento.

### Sample Variances and Correlations of Visual Acuity Measurements

Investigamos ahora el número y la forma de los patrones de datos faltantes monótonos para la agudeza visual. Primero, creamos el marco de datos armd.wide.mnt, que contiene datos solo para pacientes con patrones monótonos de nuestra muestra. Hay 140 de estos pacientes en total. 

Despues, modificamos los niveles del factor miss.pat en los datos de armd.wide.mnt con la ayuda de la función factor(). Finalmente, utilizamos la función tapply () para obtener una matriz que contiene el número de pacientes para cada patrón de datos faltantes monótonos y para cada grupo. Los resultados mostrados indican que los perfiles de valor medio para patrones de datos faltantes con un mayor número de valores faltantes, se basan en mediciones para un pequeño número de pacientes. Por lo tanto, la variabilidad de estos perfiles es mayor que para los patrones con un menor número de valores faltantes. 
```{r}
## El número de pacientes por tratamiento y patrón de datos faltantes (solo patrones monótonos)
## Subset of the data with monotone missing-data patterns
mnt.pat<- # Monotone patterns
c("----", "---X", "--XX", "-XXX", "XXXX")
armd.wide.mnt <- # Data subset
subset(my.armd.wide, miss.pat %in% mnt.pat)
dim(armd.wide.mnt) # Number of rows and cols

levels(armd.wide.mnt$miss.pat) # Some levels not needed

## Removing unused levels from the miss.pat factor
armd.wide.mnt1 <-
within(armd.wide.mnt,
{
miss.pat <- factor(miss.pat, levels=mnt.pat)
})
levels(armd.wide.mnt1$miss.pat)

## The number of patients with different monotone missing-data patterns
with(armd.wide.mnt1,
{
fl <- list(treat.f, miss.pat) # List of "by" factors
tapply(subject, fl, FUN=function(x) length(x[!is.na(x)]))
})
```

La siguiente figura muestra una matriz de diagrama de dispersión para las mediciones de agudeza visual para aquellos pacientes, para quienes todas las mediciones posteriores a la aleatorización están disponibles. Los diagramas de dispersión para los pares de variables correspondientes se dan debajo de la diagonal. El tamaño de la fuente para los coeficientes de correlación informados por encima de la diagonal es proporcional a su valor. No presentamos la sintaxis para construir la figura, ya que es bastante compleja.

```{r fig.width=7, fig.height=6}
  my.lowerPanel <-  ## pairwise.complete.obs 
  function(x, y, subscripts, ...){
  panel.grid(h = -1, v = -1) 
  panel.xyplot(x, y, ...)
  }
  my.upperPanel <-  ## pairwise.complete.obs 
  function(x, y, subscripts, ...){
  panel.xyplot(x, y, type = "n", ...)
  corx <- round(cor(x,y,use = "complete.obs"),2)
  abs.corx <- abs(corx)
  cex.value <- 3
  ltext(50,50, corx, cex = abs.corx* cex.value)
  }
  mySuperPanel <- function(z, subscripts, panel.subscripts,...){
  # z is data frame. Abbreviated variable names on the diagonal of the splom.
  panel.pairs(z, subscripts = subscripts,
  panel.subscripts = panel.subscripts,
  as.matriz = TRUE, 
  upper.panel = "my.upperPanel",
  lower.panel = "my.lowerPanel",
  prepanel.limits = function(z) return(c(1, 90))
  )}
  
  splom.form <- formula( ~cbind(vis0, vis4, vis12, vis24, vis52))
  armd.wide.tmp <- subset(my.armd.wide, miss.pat == "----",
  select = c(visual0, visual4, visual12, visual24, visual52))
  names(armd.wide.tmp) <- c("vis0", "vis4","vis12","vis24","vis52") # Short names
  
  splom.object <- splom(splom.form,
  data = armd.wide.tmp,
  par.settings = list(fontsize = list(points = 4), axis.text = list(cex = 0.9)),
  as.matriz =TRUE,  
  xlab = "",
  superpanel = mySuperPanel
  )
  print(splom.object)
```

Calculamos ahora las estimaciones de las matrices de varianza-covarianza y correlación para las mediciones de agudeza visual. Creamos para ello el marco de datos `visual.x` de la seleccion `datos.armd` seleccionando solo las cinco variables que contienen las mediciones. Luego aplicamos las funciones `var()` y `cor()` para estimar la matriz de varianza-covarianza y la matriz de correlación, respectivamente. Especificamos el argumento use = "complete.obs", que selecciona solo aquellas filas del marco de datos `visual.x` que no contienen ningún valor faltante. De esta manera, se garantiza que las matrices estimadas sean semidefinidas positivas. 

```{r}
visual.x <- subset(my.armd.wide, select = c(visual0:visual52))
(varx <- var(visual.x, use = "complete.obs")) # Var-cov mtx

print(cor(visual.x, use = "complete.obs"), # Corr mtx
digits = 2)

diag(varx) # Var-cov diagonal elements

cov2cor(varx) # Corr mtx (alternative way)
```

Una alternativa sería especificar use = "pairwise.complete.obs". En ese caso, los elementos de las matrices se estimarían utilizando datos de todos los pacientes con observaciones completas para el par particular de mediciones de agudeza visual. Esto podría dar como resultado estimaciones de varianza - covarianza o matrices de correlación, que podrían no ser semidefinidas positivas.

```{r}
(varx2 <- var(visual.x, use = "pairwise.complete.obs"))

print(cor(visual.x, use = "pairwise.complete.obs"), # Corr mtx
digits = 2)

diag(varx2)
```

La matriz de correlación estimada sugiere una correlación moderada de las mediciones. También observamos que la correlación disminuye claramente con el intervalo de tiempo.

# Modelos lineales mixtos (LMM)

Vamos a aplicar un modelo a nuestros datos que permita tener en cuenta la correlación entre las mediciones, utilizando modelos lineales de efectos mixtos (LMM). Un modelo simple asume que la relaci´on entre las variables es la misma en todos los sujetos. Sin embargo, normalmente dicho modelo no es el mismo en todos ellos, por ello en este enfoque se aplican efectos aleatorios que describen la contribución de la variabilidad en diferentes niveles de las observaciones de forma que se predice la relación entre las variables en un sentido general a la población, sin limitarnos a los datos concretos del estudio.

Ajustamos varios LMM a la selección de datos de ARMD de nuestro estudio. Para ello vamos a emplear principalmente la función `lme()` del paquete `nlme` y por 'ultimo algunos ajustados con la función `lmer()` del paquete `lme4.0`.

## A Model with Random Intercepts and Homogeneous Residual Variance

Para elegir la estructura de los efectos aleatorios es necesario incluir todos los posibles terminos fijos y sus interacciones en el modelo. Luego se comparan distintos modelos que varian en sus efectos aleatorios pero que mantienen la misma estructura fija por medio de REML. Para ello primero creamos un modelo simple que contiene intercepciones aleatorias específicas del sujeto y errores residuales homoscedásticos. 

En este modelo, asumimos que sólo hay una línea de regresión con una única constante y una única pendiente. La constante α y la pendiente β son los parámetros ﬁjos del modelo. Además, hay una constante aleatoria, $a_j$, que añade cierta cantidad de variación a la constante del modelo general en cada una de los sujetos. Se asume que esta constante aleatoria sigue una distribución normal de media 0 y varianza  $σ^2_a$ . Por lo tanto,los parámetros estimados en el modelo son cuatro, α, β, la varianza residual $σ^2$ , y la varianza de la constante  $σ&2_a$. De esta forma tenemos un modelo equivalente al modelo lineal, pero en dónde sólo es necesario estimar cuatro parámetros y en vez del mismo número que el número de sujetos estudiados. Lo que estimamos en este modelo es la varianza de esta distribución. Vamos a ajustar el modelo lineal mixto correspondiente con la función  lme() tal y como se realiza en la página 331 del capítulo 16 del libro @galecki2013linear pero para nuestro conjunto de datos:

La fórmula `lmm1` define la parte fija del modelo, incluida una interacción entre el tiempo y el tipo de tratamiento (time:treat.f). El factor *treat.f* se parametriza con "Activo" como nivel de referencia. El argumento `random = ~ 1 | subject` especifica intercepciones aleatorias específicas del sujeto. Por defecto, `lme()` asume errores residuales independientes con una varianza constante $\sigma^2$. Podemos ver la tabla de efectos fijos estimada utilizando el Función `printCoefmat()`. El argumento `has.Pvalue = TRUE` especifica que la última columna de la tabla contiene valores p. El modelo por defecto se crea según Estimación por Máxima Verosimilitud Restringida (REML)

```{r}
library(nlme)
lmm1.form <- # formula general
formula(visual ~ visual0 + time + treat.f + treat.f:time)
(lmm1 <- # se aplica el modelo, 
lme(lmm1.form,
random = ~  1|subject, data = my.armd)) # al grupo de datos reducido my.armd

summary(lmm1)

printCoefmat(summary(lmm1)$tTable, # estimated fixed-effects
has.Pvalue = TRUE, P.values = TRUE) # ... with p-values
```

Los resultados anteriores muestran que la varianza residual es $σ^2$= 8.2187 y la varianza de la constante $σ^2_a$ = 8.9159. Para la parte de los efectos ﬁjos del modelo,  α (constante)  + β·variables, la constante se estima en  α = 5.1239 y la pendiente en β de visual0 = 0.8782. Ambos parámetros son signiﬁcativamente distintos de 0. La correlación entre la constante y la pendiente de cada variable es pequeña.

Para cada sujeto, la constante aumenta o disminuye por un valor aleatorio. Este valor aleatorio sigue una distribución normal con media esperada 0 y varianza $σ^2_a$ = 8.9159. La varianza residual, es decir, el error que podemos añadir a cada una de nuestras predicciones, viene dada por $σ^2$= 8.2187.

Los valores p, que corresponden a las estadísticas de la prueba t para los coeficientes de efectos fijos (fixed-effects coefficients), los vemos también en la salida anterior, con valores significativos para *Visual0*, *time* y la interacción, sin embargo no es significativo para tipo de tratamiento (placebo y activo).

En el siguiente script, con la función `getGroupsFormula()` obtenemos información sobre la jerarquía de datos implicada por el modelo ajustado. Indica un único nivel de agrupación, definido por los niveles del sujeto. Al aplicar la funcion `getGroups()` al modelo, extraemos el factor de agrupación y lo almacenamos en el objeto `grpF`. Como vemos el factor de agrupación tiene 144 niveles (sujetos). Por ejemplo, del primer sujeto tenemos dos observaciones, para el segundo y el tercero cuatro observaciones, etc. Además obtenemos el mínimo de observaciones, que sería 1 y el máximo de observaciones es 4, como ya sabemos.

```{r}
getGroupsFormula(lmm1) # Grouping formula

str(grpF <- getGroups(lmm1)) # Grouping factor
grpF[1:17]

levels(grpF)[1:5]
range(xtabs(~grpF))
```

Para obtener más información sobre la estructura estimada de varianza-covarianza para efectos aleatorios(D) y errores residuales(Ri) del modelo, utilizamos las funciones `getVarCov()` y `VarCorr()`. El argumento `individual = "2"`, utilizado en función `getVarCov()`, solicita la matriz de varianza-covarianza de efectos aleatorios para el segundo individuo, es decir, sujeto == 2, en el conjunto de datos analizado. Sin embargo, en nuestro caso, el número de sujeto no es importante, ya que se supone que la estructura de varianza-covarianza de los efectos aleatorios es la misma para todos los individuos.

```{r}
##The D-matrix estimate
getVarCov(lmm1, individual = "2") # para obtener el valor de la varianza únicamente

VarCorr(lmm1)

## The Ri-matrix estimate
getVarCov(lmm1,
type = "conditional", # matriz estimada de varianza-covarianza Ri de los errores aleatorios residuales
individual = "2")
```

Como vemos este sujeto (número 2) tiene las cuatro mediciones de agudeza visual posteriores a la aleatorización, por lo que nos proporciona una matriz de 4 × 4. Debido a que el modelo creado supone errores residuales independientes con la misma varianza en todos los tiempos de medición, se muestra una matriz diagonal $Ri = \sigma^2 I_4 = 67.547 × I_4$

En el siguiente script calculamos la matriz de varianza-covarianza marginal estimada, aplicando la función `getVarCov()` con el argumento `type = "marginal"`. El resultado, para `individual = "2"`, se almacena en el objeto `lmm1.cov`. La varianza marginal se estima mediante la suma de la varianza residual estimada $\sigmas^2 = 67.547$ y la varianza de las intersecciones aleatorias d = 79.493.

La matriz de correlación marginal resultante se obtiene aplicando la función `cov2cor()` al primer componente de la lista de objetos `lmm1.cov`, que contiene la matriz de varianza-covarianza marginal estimada. La matriz de correlación marginal estimada implica un coeficiente de correlación positivo constante de 0.540624 para cualquiera de las dos mediciones de agudeza visual obtenidas para el mismo paciente en diferentes puntos de tiempo.

```{r}
# The estimated marginal variance-covariance matrix and the corresponding correlation matrix for model 1.
(lmm1.cov <-
getVarCov(lmm1,
type = "marginal", # Vi
individual = "2"))

(cov2cor(lmm1.cov[[1]])) # Corr(Vi)

anova(lmm1)
```

la comparación de modelos con las pruebas de razón de probabilidad es una mejor manera de probar si un parámetro es significativo. Es decir, si agregar el parámetro a su modelo mejora significativamente el ajuste del modelo, entonces ese parámetro debe incluirse en el modelo.

## A Model with Random Intercepts and the varPower(). Residual Variance-Function

Con el modelo anterior creamos este nuevo modelo `lmm2` utilizando el argumento `weights = varPower (form = ~ time)`. Para especificar el nuevo modelo, utilizamos la misma parte de efectos fijos que en el modelo`lmm1`, pero modificamos la estructura de varianza-covarianza de los errores aleatorios residuales con el uso de la función de varianza `varPower()`. La matriz diagonal Ri proporcionada por `getVarCov` ahora posee elementos desiguales definidos por la función `varPower()`. Debido a que la varianza cambia con el tiempo, los coeficientes de correlación marginal entre las observaciones realizadas en diferentes momentos ya no son iguales.

Veamos los parámetros del modelo:

```{r}
# Model 2 fitted using the function lme().
(lmm2 <- 
update(lmm1,
weights = varPower(form = ~ time), 
data = my.armd))

printCoefmat(summary(lmm2)$tTable, # Print fixed-effects
has.Pvalue = TRUE, P.values = TRUE) # ... with p-values
```

Los resultados anteriores indican que el parámetro de escala $\sigma$ se estima que es igual a 4.0999. El coeficiente de potencia $\delta$ de la función de varianza `varPower()` se estima que es igual a 0.2513. La estimación de la desviación estándar de las intersecciones aleatorias es igual a 8.1079.

Creamos ahora las estimaciones de las matrices de varianza-covarianza asociadas con modelo lmm2: D, $R_i$, y $V_i%$.

```{r}
# The estimated D, Ri, and Vi matrices for model 2
VarCorr(lmm2) #d

getVarCov(lmm2, #Ri
type = "conditional",
individual = "2")
```

La varianza estimada de las intersecciones aleatorias es igual a 65.737, menor que el valor de 79.4934 obtenida para el modelo 1 (lmm1), lo que es normal porque, al permitir errores aleatorios residuales heterocedásticos, una gran parte de la variabilidad total se explica por las variaciones residuales. De la matriz estimada de varianza-covarianza de los errores residuales $R_i$ se obtiene que el primer elemento diagonal de la matriz $R_i$ es igual a $s^2·4^{2\delta} = 4.0999 · 4^{2·0.2513} = 33.741$.

La matriz de varianza-covarianza marginal estimada $V_i$ se muestra en la salida siguiente. La matriz de correlación marginal estimada correspondiente indica una correlación decreciente entre las mediciones de agudeza visual realizadas en puntos temporales más distantes.

```{r}
(lmm2.cov <- #Vi
getVarCov(lmm2,
type = "marginal",
individual = "2"))

cov2cor(lmm2.cov[[1]]) # Corr(Vi)
```

Para resumir presento los resultados de ambos modelos en la siguiente tabla:

| modelo | Parametro | lmm1 | lmm2 |
| ------- | ------- | ------- | ------- |
| Log-REML value |   | -2004.824 | -1993.846 |
| Fixed effects |  |  |  |
|  Intercept | $\beta_0$   | 5.123917(3.19) | 3.9328(2.89) |
|  Visual acuity at t=0 | $\beta_1$   | 0.878177(0.05) | 0.9067(0.04) |
|  Time (in weeks) | $\beta_2$  | -0.150210(0.03) | -0.1637(0.03) |
|  Trt(Actv vs. Plcb) | $\beta_3$   | -0.631877(1.88) | -1.0739(1.65) |
|  Tm × Treat(Actv) | $\beta_4$    | -0.120690(0.04) | -0.1054(0.04)
| reStruct(subject) |  |  |  |
|  SD(bi0) | $\sqrt{d}$  | 8.9159 | 8.107852 |
| Variance function | |  |  |
|  Power (TIMEd) |  $\delta$ |  | 0.2513  |
| Scale | $\sigma$ | 8.2187 |  4.099941  |


## Diagnosis plots

En este punto graficamos la bondad del ajuste de ambos modelos

El gráfico que desarrolla la función `plot()` muestra los residuales condicionales de *Pearson* versus los valores ajustados. Como tal, la gráfica no es muy informativa, porque agrupa todos los residuos juntos, a pesar de que los residuos obtenidos del mismo individuo están potencialmente correlacionados. Sin embargo, puede servir para detectar, por ejemplo, valores atípicos.

En la figura 4, se observan residuos por encima y por debajo de la linea central del diagrama de diagrama de dispersión. Una gráfica modificada de los residuos para cada punto de tiempo y grupo de tratamiento podría ser más útil.

```{r}
# 1. Default residual plot of conditional Pearson residuals
plot(lmm2) 
```

Para ello se realiza el gráfico de la figura 5, donde a través del argumento `type = "pearson"` en la función `resid()` y el término `~ time | treat` se obtiene el siguiente gráfico por grupo de tratamiento a lo largo del tiempo en paneles separados. Al aplicar el argumento `id = 0.05` se etiquetan los residuos más grandes, en valor absoluto al percentil `97.5` de la distribución normal estándar por el número de la observación correspondiente a nuestros datos `my.armd`.

```{r}
# 2. Plots (and boxplots) of Pearson residuals per time and treatment
plot(lmm2, # Figure not shown
resid(., type = "pearson") ~ time | treat.f,
id = 0.05)
```

Otra opción nos la proporciona el paquete `lattice` con la función `bwplot()`:
```{r}
library(lattice)
bw1 <- # Draft plot
bwplot(resid(lmm2, type = "p") ~ time.f | treat.f,
data = my.armd0, wend = 0.05, las = 1, id = 0.05, panel = function(...) {
  panel.bwplot(..., pch = "|")
  panel.xyplot(..., jitter.x = TRUE)})
xlims <- c("Base", "4\nwks", "12\nwks", "24\nwks", "52\nwks")
update(bw1, xlim = xlims)
```

Estas figuras nos permiten una evaluación de la distribución de los residuos condicionales de Pearson para cada momento del tiempo y grupo de tratamiento. A pesar de la estandarización, la variabilidad de los residuos parece variar.

El gráfico 5 también revela una serie de valores atípicos, es decir, residuos mayores, en valor absoluto, que el percentil 97.5 de la distribución normal estándar. Como vemos los valores atípicos están presentes en todos los grupos de tratamiento y en todos los puntos de tiempo. 

Con el siguiente script se enumeran los sujetos para los que se marcaron los residuos periféricos en la figura anterior. Los datos incluidos en `outliers.idx` contiene las observaciones para las cuales el valor de la variable `idx` es igual a 1. 

```{r}
id <- 0.05 # Argument for qnorm()
outliers.idx <-
within(my.armd,
{
resid.p <- resid(lmm2, type = "pearson") # Pearson resids.
idx <- abs(resid.p) > -qnorm(id/2) # Indicator vector
})
outliers <- subset(outliers.idx, idx) # Data with outliers
nrow(outliers) # Number of outliers

outliers$subject # IDs of outliers
```

Hay 22 de esas observaciones y obtenemos el número de los sujetos correspondientes. Para varios sujetos, hay más de un residuo periférico, porque hay más de una medición de agudeza visual posible por sujeto.

La figura 7 muestra el gráfico Q-Q de los residuos condicionales de Pearson por tiempo. Los patrones muestran algunas desviaciones de una tendencia lineal. También podemos ver el gráfico `Q-Q normal` de los efectos aleatorios, ligeramente curvilíneo, lo que podría indicar la no normalidad de los efectos aleatorios.

```{r}
# 3. Normal Q-Q plots of Pearson residuals and predicted random effects
qqnorm(lmm2, ~resid(.) | time.f) # Fig. 7
qqnorm(lmm2, ~ranef(.)) 
```

La figura 8 muestra los valores observados y pronosticados de las mediciones de agudeza visual para pacientes seleccionados. La gráfica contie cuatro columnas que contienen los valores de la covariable primaria, los grupos, los valores pronosticados u observados, y el indicador del tipo del valor de la tercera columna.

```{r fig.width=7, fig.height=6}
aug.Pred <- 
augPred(lmm2,
primary = ~time, # Primary covariate
level = 0:1, # Marginal(0) and subj.-spec.(1)
length.out = 2)
plot(aug.Pred, layout = c(4, 4, 1), # Fig. 8
key = list(lines = list(lty = c(1,2)),
text = list(c("Marginal", "Subject-specific")),
columns = 2))
```

Establecemos `length.out = 2`, es decir, los valores pronosticados se obtienen en dos valores de tiempo, en el mínimo (4 semanas) y el máximo (52 semanas). 
Cada celda corresponde a un solo sujeto; así, se trazan las predicciones para los primeros 16 sujetos. Las medias de población predichas, que se muestran en la gráfica, disminuyen linealmente en el tiempo. Lo que indica que las medias de la población se desplazan para pacientes individuales mediante intercepciones aleatorias específicas del sujeto.

Para algunos pacientes, los perfiles individuales predichos obtenidos se desvían fuertemente de los observados. Por ejemplo, para los sujetos 4 y 15, los patrones individuales predichos sugieren una disminución de la agudeza visual con el tiempo, mientras que los valores observados en realidad aumentan con el tiempo. Una posible forma de mejorar las predicciones individuales es permitir no solo las intercepciones aleatorias específicas del paciente, sino también las pendientes aleatorias específicas del paciente, como haremos en el siguiente modelo.

## Models with Random Intercepts and Slopes and the varPower() Residual Variance-Function
### Model with a General Matrix D

Ajustamos el modelo siguiente `lmm3` usando la sintaxis `random = ~ 1 + time | suject` para especificar la estructura de efectos aleatorios, implicando que, para cada nivel de la variable de agrupación de sujetos, se debe considerar una intersección aleatoria y una pendiente aleatoria para el tiempo.
También se presentan los intervaloa de confianza al 95%. Los resultados muestran un bajo valor estimado del coeficiente de correlación para los efectos aleatorios $b_{0i}$ y $b_{2i}$, igual a 0.07424. El intervalo de confianza para el coeficiente de correlación sugiere que los dos efectos aleatorios pueden no estar correlacionados.

```{r}
lmm3 <- # modelo 3
update(lmm2,
random = ~1 + time | subject,
data = my.armd)
getVarCov(lmm3, individual = "2") # D

intervals(lmm3, which = "var-cov") # 95% CI for qD, d, s
```

### 16.4.2 Model with a Diagonal Matrix D

Creamos el modelo 4 `lmm4` especificando `random = pdDiag (~ time)` de forma que implicamos una forma diagonal de la matriz de varianza-covarianza D de las intersecciones y pendientes aleatorias. Seg'un los IC del 95% para todos los parámetros del modelo 4, se sugiere que la estructura media podría simplificarse eliminando la interacción `time: treat.f`.

```{r}
lmm4 <- # modelo 4
update(lmm3,
random = list(subject = pdDiag(~time)), # Diagonal D
data = my.armd)
intervals(lmm4) # 95% CI for b, qD, d, s
```

Aplicamos la función `anova()` a los modelo 3 (alternativo) y 4 (nulo). Ya que ambos modelos tienen la misma estructura media, el uso de la prueba LR basada en REML está justificado.

```{r}
anova(lmm4, lmm3) # H0: d12=0 (modelo 4 ⊂ modelo 3)
```

El resultado no es estadísticamente significativo al nivel de significancia del 5%. Indica que, al suponer una estructura diagonal más simple de la matriz D, no empeoramos el ajuste del modelo. Lo mismo nos indican los valores AIC: el valor de 3949.827 para el modelo 3 es ligeramente mayor que el valor de 3948.027 para el modelo 4, lo que indica un ajuste ligeramente mejor del último modelo.

Como los valores de la diagonal de la matriz D y $\sigma$ son positivos, nos indica que la función aumenta con el tiempo, lo que está concuerda con la observación del análisis exploratorio.

La figura 9 presenta los residuos condicionales de Pearson para el modelo 4. En comparación con la gráfica similar para el modelo 2 muestra menos residuos con un valor absoluto mayor que el percentil 97.5 de la distribución normal estándar.
```{r}
library(lattice)
bwplot(resid(lmm4, type = "p") ~ time.f | treat.f, 
data = my.armd, panel = function(...) {
  panel.bwplot(..., pch = "|")
  panel.xyplot(..., jitter.x = TRUE)})
```

La figura 10 muestra la gráfica Q-Q normal de los residuos condicionales de Pearson por tiempo para el modelo 4 comparable a la gráfica correspondiente para el modelo 2.

```{r}
# Normal Q-Q plots of Pearson residuals
qqnorm(lmm4, ~resid(.) | time.f) 
```

La figura 11 presenta las gráficas normal Q-Q de los efectos aleatorios predichos para el modelo 4. El primer gráfico muestra las intersecciones aleatorias, similar al modelo 2 y el segundo las pendientes aleatorias. Este último está ligeramente más cerca de una línea recta que el primero.

```{r}
# 3. Normal Q-Q plots of predicted random effects
qqnorm(lmm4, ~resid(.) | time.f)
qqnorm(lmm4, ~ranef(.)) 
```

Por último la figura 12 presenta los valores marginales y específicos del sujeto predichos para el modelo 4. En el modelo 2 la misma gráfica mostró una pendiente decreciente de los perfiles individuales, la misma para todos los sujetos y en algunos, los perfiles individuales predichos se desviaron fuertemente de los observados. En este modelo en cambio, los perfiles individuales predichos siguen más de cerca los valores observados y capturan, por ejemplo, las tendencias crecientes en el tiempo, lo que indica que **el modelo 4 ofrece un mejor ajuste a los datos que el modelo 2**.

```{r fig.width=7, fig.height=6}
aug.Pred <- # augPred aplicada al modelo 4
augPred(lmm4,
primary = ~time, # Primary covariate
level = 0:1, # Marginal(0) and subj.-spec.(1)
length.out = 2)
plot(aug.Pred, layout = c(4, 4, 1), 
key = list(lines = list(lty = c(1,2)),
text = list(c("Marginal", "Subject-specific")),
columns = 2))
```

### Model with a Diagonal Matrix D and a Constant Treatment Effect

Como hemos visto en el apartado anterior, la estructura media del modelo 4 podría simplificarse eliminando la interacción `treat.f:time`.

Para ajustar el nuevo modelo `lmm5` ajustamos la formula del modelo linal (LM) y eliminamos la interacci'on, pero mantenemos el resto de variables.
```{r}
lmm5.form <- formula(visual ~ visual0 + time + treat.f) # formula
lmm5 <- # modelo 5 a partir del 4
update(lmm4,
lmm5.form, data = my.armd)

summary(lmm5)$tTable #b, se(b), t-test

# Estimaciones de efectos fijos, sus errores estándar aproximados e intervalos de confianza del 95% para los parámetros de varianza-covarianza del modelo 5.

intervals(lmm5, which = "var-cov") # 95% CI for qD, d, s
```

Como se puede observar en la salida de codigo anterior, el resultado de t-test para el factor `treat.f` es estadísticamente significativo al nivel de significancia del 5%, lo que sugiere un efecto promedio negativo independiente del tiempo del tratamiento *activo*. Los IC son muy similares al modelo 4.

En el script siguiente se muestra la matriz de varianza-covarianza marginal estimada $V_i$ que indica una tendencia creciente de variaciones de las mediciones de agudeza visual a lo largo del tiempo, mientras que la matriz de correlación correspondiente sugiere una correlación decreciente entre las mediciones obtenidas en puntos de tiempo más distantes.
```{r}
# Las estimaciones de las matrices D, Ri y Vi para el modelo 5.
VarCorr(lmm5) # D

getVarCov(lmm5, # Ri
type = "conditional", individual = "2")

(lmm5.cov <- # Vi
getVarCov(lmm5,
type = "marginal",
individual = "2"))

cov2cor(lmm5.cov[[1]]) # Corr(Vi)
```

INcluir tb una tabla con los resultados:

## An Alternative Residual Variance Function: varIdent(·)

Los modelos presentados hasta ahora se especificaron con el uso de la función de varianza `varPower()`. Sin embargo, esta puede ser una función demasiado limitada, porque supone que las variaciones de las mediciones de agudeza visual cambian como una función de potencia del tiempo de medición. Sin embargo, es posible que, una función de varianza más general, no restringida, permita obtener un mejor ajuste que la función anterior. Para ello creamos el modelo 6 y lo comparamos con el modelo 3.

```{r}
# Ajustar el modelo 6 y la función de varianza utilizando una prueba de razón de probabilidad basada en REML.
(lmm6 <- 
update(lmm3, weights = varIdent(form = ~1 | time.f)))

anova(lmm3, lmm6) # funcion varPower() frente a la funcion varIdent()
```

Realizamos ahora el test anova teniendo en cuenta último modelo (nulo) está anidado en el primero. El resultado de la prueba es estadísticamente significativa al nivel de significación del 5% y sugiere que el uso de la función de varianza `varIdent()` más general para definir la matriz Ri, proporciona un mejor ajuste que el uso de `varPower()`. Sin embargo, si miramos a los par'amteros estimados, el valor del par'ametro de la semana 52 es extremadamente pequeño (0.0001436149) y difiere sustancialmente de los valores estimados de las semanas 4, 12 y 24. Esto es sorprendente, porque todos los análisis anteriores indicaron que la varianza de la última medición de agudeza visual (en la semana 52) fue la mayor. Adem'as, si vemos los intervalos de confianza para los parámetros de varianza y covarianza, nos da el siguiente mensaje de error, lo que indica problemas con la estimación de la matriz de varianza-covarianza para las estimaciones de los parámetros:

```{r message=TRUE, warning=TRUE}
intervals(lmm6, which = "var-cov")
```

Finalmente, el problema con la convergencia del algoritmo de estimación para el modelo 6 también se refleja en el gráfico QQ normal de los residuos condicionales de Pearson, donde se observa que los residuos para la semana 52 son todos iguales a 0. Esto significa que la estimación REML, con la función `lme()` no es un valor óptimo en el modelo 6.

```{r}
# El panel durante la semana 52 indica el problema con el ajuste del modelo.
qqnorm(lmm6, ~resid(.)|time.f)
```

Puede deberse a que el modelo 6 tiene siete parámetros y dado que el número de parámetros es cercano al número de ecuaciones, puede producirse colinealidad entre los parámetros, con consecuencias en forma de problemas de convergencia del algoritmo de estimación. Por otro lado, el modelo 3 tiene menos parámetros que incluye una función de potencia de tiempo, que no es lineal. Por lo tanto, en este caso, es menos probable que aparezca la colinealidad. de esta forma, el modelo 3 impone una restricción adicional en la forma de la estructura marginal de varianza-covarianza, que parece derivar en una solución óptima.

## 16.6 Testing Hypotheses About Random Effects

Calculamos los valores de AIC de los modelos 1 al 5. Se puede ver que, por ejemplo, el AIC para el modelo 2, es decir, 4003.693, es mayor que el valor de 3949.827 para el modelo 3, lo que indica un mejor ajuste del último modelo. Además, como vimos en la figura 12, los valores predichos obtenidos para el modelo 3 están más de cerca los observados, en comparación con el modelo 2. El valor más bajo de AIC se obtiene para el modelo 4, lo que sugiere que el modelo proporciona el mejor ajuste general a los datos.

Hay que notar que ambos modelos, el 4 y el 5, son identicos en cuanto a sus efectos fijos y solo varian en sus efectos aleatorios. Para comparar los dos modelos con los mismos efectos fijos pero con distintos efectos aleatorios, usamos un test de verosimilitud. 

El AIC sugiere que el modelo 4 es mas apropiado, pero el BIC sugiere que el modelo 5 es mejor. El p-valor del test de verosimilitud indica que el modelo mas complejo (5) es el mas parsimonioso y por tanto elegiriamos este.

```{r}
# valores de Akaike’s Information Criterion para los modelos 1 al 5
AIC(lmm1, lmm2, 
lmm3, lmm4) 

lmm4.ml <- update(lmm4, method = "ML")
lmm5.ml <- update(lmm5, method = "ML")
anova(lmm4.ml, lmm5.ml) # modelo 4 y 5
```

### 16.6.1 Test for Random Intercepts

Usando el modelo 1, que contiene intercepción aleatoria, vamos a comprobar si se necesitan intercepciones aleatorias específicas del sujeto a través de una prueba anova comparando el modelo 1 y un modelo nulo basado en el modelo 1, que asume errores residuales homoscedásticos y ningún efecto aleatorio. Básicamente estamos probando la hipótesis nula de que la varianza de la intersección aleatoria es cero, que está en el límite del espacio de parámetros.

Para obtener el valor p correcto, dividimos el valor $\chi^2$ based p-value extraído del objeto `anova.res` entre 2. El p-value obtenido indica que el resultado de la prueba es estadísticamente significativo. Por ello, rechazamos la hipótesis nula de que la varianza de la distribución de las intersecciones aleatorias es igual a 0.

Empleamos tambien una alternativa usando el paquete `RLRsim`. El resultado muestra que el p-value de la prueba LR basada en REML, estimado a partir de 10,000 simulaciones, es estadísticamente significativo. 

```{r}
# 0.5 chi2_0 + 0.5chi_1 como la distribución nula

gls.1 <- # Null model
gls(lmm1.form, data = my.armd)
(anova.res <- anova(gls.1, lmm1)) # Null vs. modelo 1

(anova.res[["p-value"]][2])/2 # 0.5c20 + 0.5c21

# empleamos la función exactRLRT() para simular la distribución nula
library(RLRsim)
exactRLRT(lmm1) # alternativa
```

### 16.6.2 Test for Random Slopes

consideramos ahora un modelo con intercepciones aleatorias y pendientes no correlacionadas específicas del sujeto y errores residuales homoscedasticos independientes y emplearemos la prueba LR basada en REML para probar si se necesitan pendientes aleatorias en el modelo 7 creado en el apartado anterior. La prueba implica la comparación de dos modelos, modelo 1 (nulo) y modelo 7 (alternativa).

Hay tres formas de realizar esta prueba:

```{r}
# Modelo 7
lmm7 <- 
update(lmm4, weights = NULL, # Constant resid. variance
data = my.armd)

# 0.5 chi2_0 + 0.5chi_1 como la distribución nula
(an.res <- # modelo 1 = null
stats::anova(lmm1, lmm7)) # modelo 7 = alternative

(RLRT <- an.res[["L.Ratio"]][2]) # LR-test statistic

0.5*pchisq(RLRT, 1, lower.tail = FALSE) + 0.5*pchisq(RLRT, 2, lower.tail = FALSE)

# empleamos la función exactRLRT() para simular la distribución nula
mAux <- # Auxiliary model with ...
update(lmm1, random = ~0 + time|subject, # ... random slopes only.
data = my.armd)
exactRLRT(m = mAux, # Auxiliary model
m0 = lmm1, # null
mA = lmm7) # alternative

# empleamos la función simulate() para simular la distribución nula
lmm1.sim <- # M16.1 (null)
simulate(lmm1, m2 = lmm7, nsim = 10000) # alternative
plot(vis.lme2.sim, df = c(1, 2), 
abline = c(0,1, lty=2))
```

El valor p ajustado indica que el resultado de la prueba es estadísticamente significativa. Por lo tanto, la prueba nos permite rechazar la hipótesis nula de que la varianza de las pendientes aleatorias es igual a 0. Empleamos ademas la función `exactaRLRT()`, que solo permite efectos aleatorios independientes. El valor p simulado es esencialmente igual a 0, lo que indica que la hipótesis nula puede ser rechazada

Finalmente, la función `simulate()` se aplica para obtener una gráfica de valores p empíricos y nominales de la prueba LR.

## 16.7 Analysis Using the Function lmer()

Reajustamos los modelos 1 y 7, utilizando la función `lmer()` del paquete `lme4.0`. 

### 16.7.1 Basic Results

Los valores de las estadísticas de la prueba t para los efectos fijos se proporcionan sin ningún valor de p. Ademas se muestra la matriz de varianza-covarianza del valor fijo.
Ajustamos el modelo 1:

```{r}
# (a) Model fit and results
library(lme4)
lmm1.lmer <- 
lmer(visual ~ visual0 + time * treat.f + (1|subject),
data = my.armd)
print(lmm1.lmer, corr = FALSE) # % Corr(b)

# (b) Correlation matrix for b
vcovb <- vcov(lmm1.lmer) # % Var(b)
corb <- cov2cor(vcovb) # % Corr( b)
nms <- abbreviate(names(fixef(lmm1.lmer)), 5)
rownames(corb) <- nms
corb
```

Ajustamos el modelo 7:

```{r}
library(lme4)
# Fitting the model and extracting basic information
lmm7.lmer <- 
lmer(visual ~ visual0 + time + treat.f + treat.f:time +
(1|subject) + (0 + time|subject),
data = my.armd)
summ <- summary(lmm7.lmer)
coef(summ) # t-Table

unlist(VarCorr(lmm7.lmer)) # D. Short printout

stats::sigma(lmm7.lmer) #s

# (b) Likelihood-ratio test for the treat.f:time interaction
lmm7lmer.aux <- # Model M16.7 with ...
update(lmm7.lmer, . ~ . - treat.f:time) #... interaction omitted
anova(lmm7lmer.aux, lmm7.lmer)
```

Hemos contruido una serie de modelos con varias estructuras aleatorias: modelo 1 con intersecciones aleatorias y varianzas residuales homoscedásticas; modelo 2 con intersecciones aleatorias y variaciones residuales descritas por una función de variación em el tiempo; modelo 3 con intersecciones aleatorias correlacionadas y pendientes aleatorias y las variaciones residuales del tiempo y modelo 4 con intercepciones aleatorias independientes y pendientes aleatorias y las variaciones residuales de la potencia del tiempo. El último modelo dio un ajuste satisfactorio a los datos y nos permitió simplificar la estructura media al adoptar un efecto de tratamiento constante, como se refleja en el modelo 5.

A la vista de los reultados obtenidos, hubiese sido apropiado comenzar a partir del modelo 3, pero con el tiempo incluido en la estructura media como factor, y tratar de simplificar el modelo eliminando los efectos aleatorios del tiempo. 

```{r}
# La prueba de razón de probabilidad basada en REML para pendientes no aleatorias en el modelo 7
# Using 0.5c21+0.5c22 as the null distribution
RML0 <- logLik(lmm1.lmer) # log-REML, (null)
RMLa <- logLik(lmm7.lmer) # log-REML, (alternative)
(RLRTstat <- -2 * as.numeric(RML0 - RMLa))

.5 * pchisq(RLRTstat, 1, lower.tail = FALSE) + .5 * pchisq(RLRTstat, 2, lower.tail = FALSE) # p-value

# (b) Using the function exactRLRT() to simulate the null distribution
require(RLRsim)
mAux <- lmer(visual ~ # Auxiliary model with ...
visual0 + time + treat.f + treat.f:time +
(0 + time| subject), # ... random slopes only.
data = my.armd)
exactRLRT(m = mAux, # Auxiliary model
m0= lmm1.lmer, # (null)
mA= lmm7.lmer) # (alternative)
```
