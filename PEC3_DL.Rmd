---
title: '<center> <h1>Análisis de supervivencia y de datos longitudinales (M0-161)</h1> </center>'
author: "María Plaza García - DNI 45735741"
subtitle: '`r params$subtitulo`'
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
citecolor: blue
urlcolor: blue
output:
  html_document:
    df_print: paged
    toc: yes
    fig_caption: yes
    toc_float: true
    theme: united
    highlight: tango
    toc_depth: 3
  pdf_document: 
    fig_caption: yes
    highlight: tango
    keep_tex: yes
    latex_engine: xelatex
    number_sections: yes
    toc: yes
    toc_depth: 3
  word_document:
    toc: true
link-citations: yes
nocite: |
  @kleinbaum2010survival
  @galecki2013linear
  @therneau2014package
header-includes:
  - \usepackage[spanish]{babel}
  - \usepackage{subfig}
params:
  subtitulo: Tercera prueba de evaluación continua - dataset ARMD
  p.train: !r 150
  seed.train: 41
  seed.clsfier: 1234
bibliography: PEC3.bib
geometry: margin=2cm
---

```{r setup, include=FALSE}
require(knitr)
knitr::opts_chunk$set(
  fig.show = "hold",
  fig.align='center',
  fig.height = 4.5,
  fig.width = 5,
	message = FALSE,
	warning = FALSE,
	cache = TRUE,
	comment = NULL,
	tidy = FALSE
)
options(width=90)
Sys.setlocale("LC_TIME", "C")
```

```{r packages, message=FALSE, echo=FALSE, warning=FALSE}
libraries <- c("htmltools", "bookdown", "bibtex" ,"survival", "KMsurv",
               "survMisc", "ggfortify", "knitr", "flexsurv", "actuar", "dplyr", "printr", "nlmeU")
check.libraries <- is.element(libraries, installed.packages()[, 1])==FALSE
libraries.to.install <- libraries[check.libraries]
if (length(libraries.to.install!=0)) {
  install.packages(libraries.to.install)
}

success <- sapply(libraries,require, quietly = FALSE,  character.only = TRUE)
if(length(success) != length(libraries)) {stop("A package failed to return 
                                               a success in require() function.")}

```

**Repositorio Github:**

https://github.com/mariaplaza/PEC3_DatosLongitudinales

\pagebreak

# Introducción

Reproducir el análisis estadístico completo que se lleva a cabo en la selección de GB13 para el el conjunto ARMD para el dataset personal. Desde la presentación y descripción del dataset objeto de estudio hasta el modelo lineal mixto que se proponga, cada paso debe ser oportunamente motivado y razonado, con la interpretación final de los resultados.

# Datos
## Selección de la muestra estudio

Vamos a emplear los datos ARMD disponibles en el paquete `nlmeU` como data frame. Los datos de ARMD surgen de un ensayo clínico aleatorizado multicéntrico que compara un tratamiento experimental (interferón alfa) versus placebo para pacientes diagnosticados con ARMD, de las siglas en inglés, Age-Related Macular Degeneration (La degeneración macular relacionada con la edad).

```{r}
library(nlmeU)
attach(armd.wide)
attach(armd0)
attach(armd)
dim(armd.wide)
str(armd.wide)
dim(armd0)
```

Vemos que se trata de un data frame con datos de 240 pacientes sobre 10 variables de tipo numéricas y facores.

En primer lugar debemos hacer una selección del dataset con la información de 150 individuos escogidos de forma aleatoria del dataset original `armd.wide`, a partir de las dos últimas cifras del NIF, en este caso *41*, siguiendo las siguientes indicaciones:

```{r}
#fijamos la semilla para el generador pseudoaleatorio
set.seed(params$seed.train) 
# creamos la muestra de 150 individuos
muestra<-sample(1:nrow(armd.wide),params$p.train)
my.armd.wide <- data.frame(armd.wide[muestra,])
dim(my.armd.wide) # vemos que se ha creado adecuadamente
# write.csv(my.armd.wide, "./my.armd.wide.csv") # guardamos la seleccion
head(my.armd.wide)
```

Con los datos de estos pacientes, reducimos los otros dos conjuntos de datos de armd, armd y armd0, para que contengan los datos de los mismos pacientes de mi selección. Tenemos por tanto, tres conjunto de datos de 150 pacientes en tres diferentes data.frame:

```{r}
library(dplyr)
my.armd0 <- filter(armd0, subject %in% my.armd.wide$subject)
dim(my.armd0)

library(dplyr)
my.armd <- filter(armd, subject %in% my.armd.wide$subject)
dim(my.armd)
```

Veamos cuales de las características actúan como factores:
```{r}
(facs <- sapply(my.armd.wide, is.factor))

names(facs[facs == TRUE])
```

Interesante es el factor `miss.pat`, creado con los valores de las columnas visual4, visual12, visual24, y visual52. Los elementos del vector `miss.pat` resultante indican que, por ejemplo, para el paciente 163 en el marco de datos faltaban mediciones de agudeza visual en la semana 24 y 52, mientras que para paciente 5, no se obtuvieron mediciones de agudeza visual en cualquier visita posterior a la aleatorización inicial.

## Exploración de la muestra estudio
### ARMD Trial: Visual Acuity

En los datos de ARMD, estamos interesados principalmente en el efecto del tratamiento sobre las mediciones de agudeza visual. Por lo tanto, en la Fig. 3.1, primero observamos las mediciones trazándolas contra el tiempo para varios pacientes seleccionados de ambos grupos de tratamiento. Más específicamente, seleccionamos cada 10 pacientes de cada grupo. En base a los gráficos que se muestran en la figura 3.1, se pueden realizar varias observaciones

```{r}
library(lattice)

xy1 <- # Draft plot
xyplot(visual ~ jitter(time) | treat.f,
groups = subject,
data = my.armd0,
type = "l", lty = 1)
update(xy1, # Fig. 3.1
xlab = "Time (in weeks)",
ylab = "Visual acuity",
grid = "h")


library(ggplot2)
library(nlmeU) 
ggplot(my.armd0, aes(x=time, y=visual, group=subject, color=treat.f)) + geom_line()+geom_point()+xlab("Tiempo (semanas)")+ylab("Agudeza Visual")
```

### Patterns of Missing Data

Inspección de patrones de datos faltantes en los datos de armd.wide para las mediciones de agudeza visual posteriores a la aleatorización utilizando tres métodos diferentes

```{r}
table(my.armd.wide$miss.pat)

with(my.armd.wide, table(miss.pat))

xtabs(~miss.pat, my.armd.wide)
```

También vale la pena señalar que hay seis (= 3 + 1 + 1 + 1) pacientes con cuatro patrones diferentes de datos faltantes no monótonos, es decir, con mediciones intermitentes de agudeza visual faltante. Al modelar datos con tales patrones, se necesita un cuidado adicional al especificar estructuras de varianza-covarianza. 

### Mean-Value Profiles

En esta sección, investigamos el número de valores faltantes y calculamos las medias de muestra de las mediciones de agudeza visual para diferentes visiones y grupos de tratamiento.

```{r}
# Counts of nonmissing visual acuity measurements
attach(my.armd0)
flst <- list(time.f, treat.f) # "By" factors
(tN <- # Counts
tapply(visual, flst,
FUN = function(x) length(x[!is.na(x)])))
```

Como resultado, obtenemos una matriz con el número de mediciones de agudeza visual que no faltan para cada visita y cada grupo de tratamiento. Almacenamos la matriz en el objeto tN. La visualización de la matriz indica que no faltaron mediciones al inicio. En general, hay más mediciones faltantes en el grupo de tratamiento activo.

En la siguiente tabla, empleamos de nuevo la función `tapply()` dos veces para calcular las medias y las medianas de la muestra de las mediciones de agudeza `visual0` para cada combinación de los niveles de factores line0 y treat.f. Almacenamos los resultados en matrices tMn y tMd, respectivamente. Luego creamos la matriz `res` combinando matrices tN, tMn y tMn por columnas. Finalmente, para mejorar la legibilidad de las pantallas, modificamos los nombres de las columnas de resolución.

A partir de la visualización de la matriz de resolución, se concluye que, en promedio, hubo muy poca diferencia en la agudeza visual entre los dos grupos de tratamiento al inicio del estudio. Durante el curso del estudio, la agudeza visual media disminuyó con el tiempo en ambos grupos. El valor medio es consistentemente mayor en el grupo placebo.

```{r}
# Sample means and medians of visual acuity measurements
attach(my.armd0)
tMn <- tapply(visual, flst, FUN = mean) # Sample means
tMd <- tapply(visual, flst, FUN = median) # Sample medians
colnames(res <- cbind(tN, tMn, tMd)) # Column names

nms1 <- rep(c("P", "A"), 3)
nms2 <- rep(c("n", "Mean", "Mdn"), rep(2, 3))
colnames(res) <- paste(nms1, nms2, sep = ":") # New column names
res
detach(my.armd0)
```

La siguiente figura muestra gráficos de caja para la agudeza visual de los cinco puntos temporales y los dos grupos de tratamiento.

```{r}
library(lattice)
bw1 <- # Draft plot
bwplot(visual ~ time.f | treat.f,
data = my.armd0)
xlims <- c("Base", "4\nwks", "12\nwks", "24\nwks", "52\nwks")
update(bw1, xlim = xlims, pch = "|") # Final plot
```

Las gráficas de caja y bigotes ilustran los patrones implicados por las medias y medianas de muestra, presentadas en el Panel R3.3b. La disminución de los valores medios en el tiempo se ve claramente para ambos grupos de tratamiento. Es más pronunciado para el brazo de tratamiento activo. Como hubo un abandono ligeramente mayor en ese brazo, una posible explicación podría ser que los pacientes cuya agudeza visual mejoró abandonaron el estudio. En tal caso, se observaría una progresión más rápida de la enfermedad en ese brazo de tratamiento.

### Sample Variances and Correlations of Visual Acuity Measurements

Investigamos ahora el número y la forma de los patrones de datos faltantes monótonos para la agudeza visual. Primero, creamos el marco de datos armd.wide.mnt, que contiene datos solo para pacientes con patrones monótonos de nuestra muestra. Hay 140 de estos pacientes en total. 

Despues, modificamos los niveles del factor miss.pat en los datos de armd.wide.mnt con la ayuda de la función factor(). Finalmente, utilizamos la función tapply () para obtener una matriz que contiene el número de pacientes para cada patrón de datos faltantes monótonos y para cada grupo. Los resultados mostrados indican que los perfiles de valor medio para patrones de datos faltantes con un mayor número de valores faltantes, se basan en mediciones para un pequeño número de pacientes. Por lo tanto, la variabilidad de estos perfiles es mayor que para los patrones con un menor número de valores faltantes. 
```{r}
## El número de pacientes por tratamiento y patrón de datos faltantes (solo patrones monótonos)
## Subset of the data with monotone missing-data patterns
mnt.pat<- # Monotone patterns
c("----", "---X", "--XX", "-XXX", "XXXX")
armd.wide.mnt <- # Data subset
subset(my.armd.wide, miss.pat %in% mnt.pat)
dim(armd.wide.mnt) # Number of rows and cols

levels(armd.wide.mnt$miss.pat) # Some levels not needed

## Removing unused levels from the miss.pat factor
armd.wide.mnt1 <-
within(armd.wide.mnt,
{
miss.pat <- factor(miss.pat, levels=mnt.pat)
})
levels(armd.wide.mnt1$miss.pat)

## The number of patients with different monotone missing-data patterns
with(armd.wide.mnt1,
{
fl <- list(treat.f, miss.pat) # List of "by" factors
tapply(subject, fl, FUN=function(x) length(x[!is.na(x)]))
})
```

La siguiente figura muestra una matriz de diagrama de dispersión para las mediciones de agudeza visual para aquellos pacientes, para quienes todas las mediciones posteriores a la aleatorización están disponibles. Los diagramas de dispersión para los pares de variables correspondientes se dan debajo de la diagonal. El tamaño de la fuente para los coeficientes de correlación informados por encima de la diagonal es proporcional a su valor. No presentamos la sintaxis para construir la figura, ya que es bastante compleja.

```{r fig.width=7, fig.height=6}
  my.lowerPanel <-  ## pairwise.complete.obs 
  function(x, y, subscripts, ...){
  panel.grid(h = -1, v = -1) 
  panel.xyplot(x, y, ...)
  }
  my.upperPanel <-  ## pairwise.complete.obs 
  function(x, y, subscripts, ...){
  panel.xyplot(x, y, type = "n", ...)
  corx <- round(cor(x,y,use = "complete.obs"),2)
  abs.corx <- abs(corx)
  cex.value <- 3
  ltext(50,50, corx, cex = abs.corx* cex.value)
  }
  mySuperPanel <- function(z, subscripts, panel.subscripts,...){
  # z is data frame. Abbreviated variable names on the diagonal of the splom.
  panel.pairs(z, subscripts = subscripts,
  panel.subscripts = panel.subscripts,
  as.matriz = TRUE, 
  upper.panel = "my.upperPanel",
  lower.panel = "my.lowerPanel",
  prepanel.limits = function(z) return(c(1, 90))
  )}
  
  splom.form <- formula( ~cbind(vis0, vis4, vis12, vis24, vis52))
  armd.wide.tmp <- subset(my.armd.wide, miss.pat == "----",
  select = c(visual0, visual4, visual12, visual24, visual52))
  names(armd.wide.tmp) <- c("vis0", "vis4","vis12","vis24","vis52") # Short names
  
  splom.object <- splom(splom.form,
  data = armd.wide.tmp,
  par.settings = list(fontsize = list(points = 4), axis.text = list(cex = 0.9)),
  as.matriz =TRUE,  
  xlab = "",
  superpanel = mySuperPanel
  )
  print(splom.object)
```

Calculamos ahora las estimaciones de las matrices de varianza-covarianza y correlación para las mediciones de agudeza visual. Creamos para ello el marco de datos `visual.x` de la seleccion `datos.armd` seleccionando solo las cinco variables que contienen las mediciones. Luego aplicamos las funciones `var()` y `cor()` para estimar la matriz de varianza-covarianza y la matriz de correlación, respectivamente. Especificamos el argumento use = "complete.obs", que selecciona solo aquellas filas del marco de datos `visual.x` que no contienen ningún valor faltante. De esta manera, se garantiza que las matrices estimadas sean semidefinidas positivas. 

```{r}
visual.x <- subset(my.armd.wide, select = c(visual0:visual52))
(varx <- var(visual.x, use = "complete.obs")) # Var-cov mtx

print(cor(visual.x, use = "complete.obs"), # Corr mtx
digits = 2)

diag(varx) # Var-cov diagonal elements

cov2cor(varx) # Corr mtx (alternative way)
```

Una alternativa sería especificar use = "pairwise.complete.obs". En ese caso, los elementos de las matrices se estimarían utilizando datos de todos los pacientes con observaciones completas para el par particular de mediciones de agudeza visual. Esto podría dar como resultado estimaciones de varianza - covarianza o matrices de correlación, que podrían no ser semidefinidas positivas.

```{r}
(varx2 <- var(visual.x, use = "pairwise.complete.obs"))

print(cor(visual.x, use = "pairwise.complete.obs"), # Corr mtx
digits = 2)

diag(varx2)
```

La matriz de correlación estimada sugiere una correlación moderada de las mediciones. También observamos que la correlación disminuye claramente con el intervalo de tiempo.

# Modelos

Vamos a aplicar un modelo a nuestros datos que permite tener en cuenta la correlación entre las mediciones,utilizando modelos lineales de efectos mixtos (LMM). En este enfoque, la estructura jerárquica de los datos se aborda directamente, con efectos aleatorios que describen la contribución de la variabilidad en diferentes niveles de la jerarquía a la variabilidad total de las observaciones.

Ajustamos varios LMM a la seleccion de datos de ARMD de nuestro estudio. Para ello vamos a emplear principalmente la función `lme()` del paquete `nlme`, algunos ajustados con la función `lmer()` del paquete `lme4.0`.

## A Model with Random Intercepts and Homogeneous Residual Variance

Vamos a realizar un modelo simple que contiene intercepciones aleatorias específicas del sujeto y errores residuales homoscedásticos.

La fórmula `lm2.form` define la parte fija del modelo, incluida una interacción entre *line* y el *tratamiento*. El factor *treat.f* se parametriza con "Activo" como nivel de referencia. El argumento `random = ~ 1 | subject` especifica intercepciones aleatorias específicas del sujeto. Por defecto, `lme()` asume errores residuales independientes con una varianza constante $\sigma^2$. Además, se usa la estimación REML predeterminada. Para cambiarlo a la estimación de ML, debemos agregar el argumento method = "ML" a la llamada a la función.

Imprimimos la tabla de efectos fijos estimada utilizando el Función `printCoefmat()`. El argumento `has.Pvalue = TRUE` especifica que la última columna de la tabla contiene valores p que deben imprimirse.

**Model M16.1 fitted using the function lme()**

Ajustamos el modelo con las variabes que nos dan un menor p-value y con la variable factor treat.f:

```{r}
library(nlme)
lm2.form <- # (16.1)
formula(visual ~ visual0 + time + treat.f + treat.f:time)
(fm16.1 <- # M16.1
lme(lm2.form,
random = ~  1|subject, data = my.armd, na.action=na.omit, method = "ML"))

printCoefmat(summary(fm16.1)$tTable, # Print fixed-effects, etc.
has.Pvalue = TRUE, P.values = TRUE) # ... with p-values
```

Los resultados anteriores muestran que la desviación estándar de las intersecciones aleatorias se estima que es igual a 0.46, mientras que la desviación estándar residual $\sigma$ es igual a 0.17.

Ahora extraemos información sobre la agrupación de datos. Al usar la función `getGroupsFormula()` obtenemos la expresión de condicionamiento utilizada en la especificación del argumento aleatorio. Indica un único nivel de agrupación, definido por los niveles del sujeto. Al aplicar la funcion `getGroups()` al objeto de ajuste del modelo, extraemos el factor de agrupación y lo almacenamos en el objeto `grpF`. Con la ayuda de la función `str()`, mostramos la estructura del objeto. La impresión implica que el factor de agrupación tiene 118 (sujetos).

```{r}
getGroupsFormula(fm16.1) # Grouping formula

str(grpF <- getGroups(fm16.1)) # Grouping factor
grpF[1:17]

levels(grpF)[1:5]
range(xtabs(~grpF))
```

Para obtener más información sobre la estructura estimada de varianza-covarianza para efectos aleatorios (D) y errores residuales (Ri) del modelo, utilizamos las funciones `getVarCov()` y `VarCorr()`. El argumento `individual = "2"`, utilizado en función `getVarCov()`, solicita la matriz de varianza-covarianza de efectos aleatorios para el segundo individuo, es decir, sujeto == 2, en el conjunto de datos analizado. De hecho, en nuestro caso, el número de sujeto no es importante, ya que se supone que la estructura de varianza-covarianza de los efectos aleatorios es la misma para todos los individuos. Obtenemos las estimaciones de los elementos de la matriz D utilizando la función `VarCorr()`.

```{r}
##The D-matrix estimate
getVarCov(fm16.1, individual = "2")

VarCorr(fm16.1)

## The Ri-matrix estimate
getVarCov(fm16.1,
type = "conditional",
individual = "2")
```

Obtenemos la medicion de agudeza visual posteriora la aleatorización, por lo que se forma una matriz de un solo valor. La varianza marginal se estima mediante la suma de la varianza residual estimada s 2 = 0.091131 y la varianza del azar = 0.64804. El último componente de la varianza se convierte en la covarianza.

La matriz de correlación marginal resultante se obtiene aplicando la función `cov2cor()` al primer componente de la lista de objetos fm16.1cov, que contiene la matriz de varianza-covarianza marginal estimada. La matriz de correlación marginal estimada implica un coeficiente de correlación positivo constante de 0.52 para cualquiera de las dos mediciones de agudeza visual obtenidas para el mismo paciente en diferentes puntos de tiempo.

```{r}
# The estimated marginal variance-covariance matrix and the corresponding correlation matrix for model M16.1. The model-fit object fm16.1 was created in Panel R16.1
(fm16.1cov <-
getVarCov(fm16.1,
type = "marginal", # Vi
individual = "2"))

(cov2cor(fm16.1cov[[1]])) # Corr(Vi)
```

Con el modelo anterior creamos este nuevo modelo: **Modelo 2**

```{r}
# Model M16.2 fitted using the function lme(). The model-fit object fm16.1 was created in Panel R16.1
(fm16.2 <- 
update(fm16.1,
weights = varPower(form = ~ time), 
data = my.armd))
```



```{r}
# The estimated D, Ri, and Vi matrices for model M16.2. The model-fit object fm16.2 was created in Panel R16.5
VarCorr(fm16.2) #d

getVarCov(fm16.2, #Ri
type = "conditional",
individual = "2")

(fm16.2cov <- #Vi
getVarCov(fm16.2,
type = "marginal",
individual = "2"))

cov2cor(fm16.2cov[[1]]) # Corr(Vi)
```

Crear una tabla con los resultados de los tres modelos: ARMD Trial: REML-based estimatesa for linear mixed-effects modelsb with random intercepts and time slopes


## Diagnosis plots

ARMD Trial: Residual plots for model M16.2. The model-fit object fm16.2 was created in Panel R16.5

```{r}
library(lattice)
# 1. Default residual plot of conditional Pearson residuals
plot(fm16.2) # Fig. 16.1
# 2. Plots (and boxplots) of Pearson residuals per time and treatment
plot(fm16.2, # Figure not shown
resid(., type = "pearson") ~ time | treat.f,
id = 0.05)
bwplot(resid(fm16.2, type = "p") ~ time.f | treat.f, # Fig. 16.2
panel = lattice.getOption("panel.xyplot"), # User-defined panel (not shown)
data = my.armd)
# 3. Normal Q-Q plots of Pearson residuals and predicted random effects
qqnorm(fm16.2, ~resid(.) | time.f) # Fig. 16.3
qqnorm(fm16.2, ~ranef(.)) # Fig. 16.4
```

*Residual plots for model M16.2. The model-fit object fm16.2 was created in Panel R16.5*

```{r}
id <- 0.05 # Argument for qnorm()
outliers.idx <-
within(my.armd,
{
resid.p <- resid(fm16.2, type = "pearson") # Pearson resids.
idx <- abs(resid.p) > -qnorm(id/2) # Indicator vector
})
outliers <- subset(outliers.idx, idx) # Data with outliers
nrow(outliers) # Number of outliers

outliers$subject # IDs of outliers
```

*Predicted visual acuity values for model M16.2. The model-fit object fm16.2 was created in Panel R16.5*

```{r fig.width=7, fig.height=6}
aug.Pred <- # augPred for M16.2
augPred(fm16.2,
primary = ~time, # Primary covariate
level = 0:1, # Marginal(0) and subj.-spec.(1)
length.out = 2)
plot(aug.Pred, layout = c(4, 4, 1), # Fig. 16.5
key = list(lines = list(lty = c(1,2)),
text = list(c("Marginal", "Subject-specific")),
columns = 2))
```

## Models with Random Intercepts and Slopes and the varPower(·) Residual Variance-Function
### Model with a General Matrix D

La matriz D estimada y los intervalos de confianza para los parámetros qD para el modelo M16.3. El objeto de ajuste del modelo fm16.2 se hizo reaccionar en el Panel R16.5

```{r}
fm16.3 <- # M16.3 ← M16.2
update(fm16.2,
random = ~1 + time | subject,
data = my.armd)
getVarCov(fm16.3, individual = "2") # D: (16.16)

intervals(fm16.3, which = "var-cov") # 95% CI for qD, d: (16.8), s
```

### 16.4.2 Model with a Diagonal Matrix D

Confidence intervals for the parameters of model M16.4. The model-fit object fm16.3 was created in Panel R16.10

```{r}
fm16.4 <- # M16.4 ← M16.3
update(fm16.3,
random = list(subject = pdDiag(~time)), # Diagonal D
data = my.armd)
intervals(fm16.4) # 95% CI for b, qD, d, s
```

Testing a null hypothesis about the qD parameters for model M16.4. The model-fit object fm16.3 was created in Panel R16.10

```{r}
anova(fm16.4, fm16.3) # H0: d12=0 (M16.4 ⊂ M16.3)
```

Stripplots (and box-and-whiskers plots) of the conditional Pearson residuals for each timepoint and treatment group for model:

```{r}
library(lattice)
bwplot(resid(fm16.4, type = "p") ~ time.f | treat.f, 
data = my.armd, panel = function(...) {
  panel.bwplot(..., pch = "|")
  panel.xyplot(..., jitter.x = TRUE)})
```

Normal Q-Q plots of Pearson residuals and predicted random effects

```{r}
# 3. Normal Q-Q plots of Pearson residuals and predicted random effects
qqnorm(fm16.4, ~resid(.) | time.f) # Fig. 16.3
qqnorm(fm16.4, ~ranef(.)) # Fig. 16.4
```

Observed and predicted values of visual acuity for selected patients for model M16.4

```{r fig.width=7, fig.height=6}
aug.Pred <- # augPred for M16.2
augPred(fm16.4,
primary = ~time, # Primary covariate
level = 0:1, # Marginal(0) and subj.-spec.(1)
length.out = 2)
plot(aug.Pred, layout = c(4, 4, 1), # Fig. 16.5
key = list(lines = list(lty = c(1,2)),
text = list(c("Marginal", "Subject-specific")),
columns = 2))
```

## Model with a Diagonal Matrix D and a Constant Treatment Effect

Fixed-effects estimates, their approximate standard errors, and 95% confidence intervals for the variance-covariance parameters of model M16.5. The model-fit object fm16.4 was created in Panel

```{r}
lm3.form <- formula(visual ~ visual0 + time + treat.f) # (12.9)
fm16.5 <- # M16.5 ← M16.4
update(fm16.4,
lm3.form, data = my.armd)
summary(fm16.5)$tTable #b, se(b), t-test

intervals(fm16.5, which = "var-cov") # 95% CI for qD, d, s
```

The estimates of matrices D, Ri, and Vi for model M16.5. The model-fit object fm16.5 was created in Panel R16.13

```{r}
VarCorr(fm16.5) # D: (16.16),

getVarCov(fm16.5, # Ri: (16.8)
type = "conditional", individual = "2")

(fm16.5cov <- # Vi: (16.9)
getVarCov(fm16.5,
type = "marginal",
individual = "2"))

cov2cor(fm16.5cov[[1]]) # Corr(Vi)
```

## An Alternative Residual Variance Function: varIdent(·)

INcluir tb una tabla con los resultados:
REML-based estimatesa for linear mixed-effects models with random intercepts and slopes

Fitting model M16.6 and testing its variance function using a REML-based likelihood-ratio test. The model-fit object fm16.3 was created in Panel R16.10

```{r}
# (a) Fitting of model M16.6
(fm16.6 <- # M16.6 ← M16.3
update(fm16.3, weights = varIdent(form = ~1 | time.f)))
```


```{r}

anova(fm16.3, fm16.6) # varPower (M16.3) ⊂ varIdent (M16.6)

# A signal of the problems with the estimation of model M16.6 can be also obtained by, e.g., attempting to compute confidence intervals for the variancecovariance parameters. In particular, issuing the command results in an error message indicating problems with estimating the variancecovariance matrix for the estimates of the parameters.

# intervals(fm16.6, which = "var-cov")

# Finally, the problem with convergence of the estimation algorithm for model M16.6 is also clearly reflected in the normal Q-Q plot of the conditional Pearson residuals, shown in Fig. 16.10 and obtained by issuing the command.

qqnorm(fm16.6, ~resid(.)|time.f)

# The normal Q-Q plot of the conditional Pearson residuals for model M16.6. Panel for 52 weeks indicates the problem with model fit. This means that the REML estimate, reported by the lme() function in Panel R16.14a, is not an optimum value.

```

```{r}
# densityplot(fm16.3)
```

## 16.6 Testing Hypotheses About Random Effects

The values of Akaike’s Information Criterion for models M16.1–M16.5

```{r}
AIC(fm16.1, fm16.2, # M16.1, M16.2
fm16.3, fm16.4) # M16.3, M16.4

fm16.4ml <- update(fm16.4, method = "ML")
fm16.5ml <- update(fm16.5, method = "ML")
anova(fm16.4ml, fm16.5ml) # M16.4 ⊂ M16.5
```

### 16.6.1 Test for Random Intercepts

The REML-based likelihood-ratio test for no random intercepts in model M16.1. The formula-object lm2.form and the model-fit object fm16.1 were created in Panel R16.1

```{r}
# (a) Using 0.5c20 +0.5c21 as the null distribution

vis.gls1a <- # Null model
gls(lm2.form, data = my.armd)
(anova.res <- anova(vis.gls1a, fm16.1)) # Null vs. M16.1

(anova.res[["p-value"]][2])/2 # 0.5c20 + 0.5c21

# (b) Using the function exactRLRT() to simulate the null distribution
library(RLRsim)
exactRLRT(fm16.1) # M16.1 (alternative)
```

### 16.6.2 Test for Random Slopes

The REML-based likelihood-ratio test for random slopes for model M16.7. The model-fit objects fm16.1 and fm16.4 were created in Panels R16.1 and R16.10, respectively.

```{r}
# (a) Fitting model M16.7
fm16.7 <- # M16.7 ← M16.4
update(fm16.4, weights = NULL, # Constant resid. variance
data = my.armd)
# (b) Using 0.5c21+0.5c22 as the null distribution
(an.res <- # M16.1 (null)
anova(fm16.1, fm16.7)) # M16.7 (alternative)

(RLRT <- an.res[["L.Ratio"]][2]) # LR-test statistic

0.5*pchisq(RLRT, 1, lower.tail = FALSE) + 0.5*pchisq(RLRT, 2, lower.tail = FALSE)

# (c) Using the function exactRLRT() to simulate the null distribution
mAux <- # Auxiliary model with ...
update(fm16.1, random = ~0 + time|subject, # ... random slopes only.
data = my.armd)
exactRLRT(m = mAux, # Auxiliary model
m0 = fm16.1, # M16.1 (null)
mA = fm16.7) # M16.7 (alternative)

# (d) Using the function simulate() to simulate the null distribution
vis.lme2.sim <- # M16.1 (null)
simulate(fm16.1, m2 = fm16.7, nsim = 10000) # M16.7 (alternative)
plot(vis.lme2.sim, df = c(1, 2), # Fig. 16.12
abline = c(0,1, lty=2))
```

## 16.7 Analysis Using the Function lmer()
### 16.7.1 Basic Results

```{r}
# (a) Model fit and results
require(lme4.0)
fm16.1mer <- # M16.1
lmer(visual ~ visual0 + time * treat.f + (1|subject),
data = my.armd)
print(fm16.1mer, corr = FALSE) # % Corr(b) not printed

# (b) Correlation matrix for b
vcovb <- vcov(fm16.1mer) # % Var(b)
corb <- cov2cor(vcovb) # % Corr( b)
nms <- abbreviate(names(fixef(fm16.1mer)), 5)
rownames(corb) <- nms
corb
```


```{r}
library(lme4)
# (a) Fitting the model and extracting basic information
fm16.2mer <- # M16.7
lmer(visual ~ visual0 + time + treat.f + treat.f:time +
(1|subject) + (0 + time|subject),
data = my.armd)
summ <- summary(fm16.2mer)
coef(summ) # t-Table

unlist(VarCorr(fm16.2mer)) # D. Short printout

sigma(fm16.2mer) #s

# (b) Likelihood-ratio test for the treat.f:time interaction
fm16.2aux <- # Model M16.7 with ...
update(fm16.2mer, . ~ . - treat.f:time) #... interaction omitted
anova(fm16.2aux, fm16.2mer)
```

The REML-based likelihood-ratio test for no random slopes in model M16.7. Model-fit objects fm16.1mer and fm16.2mer were created in Panels R16.19 and R16.26, respectively

```{r}
# (a) Using 0.5c21+0.5c22 as the null distribution
RML0 <- logLik(fm16.1mer) # log-REML, M16.1 (null)
RMLa <- logLik(fm16.2mer) # log-REML, M16.7 (alternative)
(RLRTstat <- -2 * as.numeric(RML0 - RMLa))

.5 * pchisq(RLRTstat, 1, lower.tail = FALSE) + .5 * pchisq(RLRTstat, 2, lower.tail = FALSE) # p-value

# (b) Using the function exactRLRT() to simulate the null distribution
require(RLRsim)
mAux <- lmer(visual ~ # Auxiliary model with ...
visual0 + time + treat.f + treat.f:time +
(0 + time| subject), # ... random slopes only.
data = my.armd)
exactRLRT(m = mAux, # Auxiliary model
m0= fm16.1mer, # M16.1 (null)
mA= fm16.2mer) # M16.7 (alternative)
```

Tabla con todos los resultados!!!
